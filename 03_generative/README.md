# Are generative classifiers more robust to adversarial attacks? 

Paper: [Li et al. 2018](https://arxiv.org/abs/1802.06552)

## Setup

Run `./setup.sh` to fetch models.

## Evaluation 

* Random attack
* Loss function decomposition
* PGD on the cross-entropy loss 
* Feature adversaries (logit layer)
* Feature adversaries (input layer)
